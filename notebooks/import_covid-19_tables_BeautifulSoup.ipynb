{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import all tables from website contain all covid_19 tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_url = 'https://covidtracking.com'\n",
    "response = requests.get(website_url)\n",
    "\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'requests.models.Response'>\n"
     ]
    }
   ],
   "source": [
    "print(type(response))\n",
    "#response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title data-react-helmet=\"true\">The COVID Tracking Project | The COVID Tracking Project</title>\n"
     ]
    }
   ],
   "source": [
    "soup = BS(response.content, 'lxml')\n",
    "print(soup.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create tow lists of states names because the codes breakes when calling 50 states at once due to connection problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##dont run this cell if you run the second list \n",
    "#first list of state names\n",
    "state_names=['alabama',\n",
    "             'alaska',\n",
    "            #'american-samoa',\n",
    "             'arizona',\n",
    "             'arkansas',\n",
    "            'california',\n",
    "            'colorado',\n",
    "            'connecticut',\n",
    "            'delaware',\n",
    "            'district-of-columbia',\n",
    "            'florida'\n",
    "            'georgia',\n",
    "            'hawaii',\n",
    "            'idaho',\n",
    "            'illinois',\n",
    "            'indiana',]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont run this cell if you run the fisrt list \n",
    "#second list of state names\n",
    "state_names=['iowa',\n",
    "            'kansas',\n",
    "            'kentucky',\n",
    "            'louisiana',\n",
    "            'maine',\n",
    "           'maryland',\n",
    "           'massachusetts',\n",
    "           'michigan',\n",
    "            'minnesota',\n",
    "            'mississippi',\n",
    "             'missouri',\n",
    "            'montana',\n",
    "            'nebraska',\n",
    "            'nevada',\n",
    "            'new-hampshire',\n",
    "            'new-jersey',\n",
    "            'new-mexico',\n",
    "            'new-york',\n",
    "            'north-carolina',\n",
    "            'north-dakota',\n",
    "            'ohio',\n",
    "            'oklahoma',\n",
    "            'oregon',\n",
    "            'pennsylvania',\n",
    "            'rhode-island',\n",
    "            'south-carolina',\n",
    "            'south-dakota',\n",
    "            'tennessee',\n",
    "            'texas',\n",
    "            'utah',\n",
    "            'vermont',\n",
    "            'virginia',\n",
    "            'washington',\n",
    "            'west-virginia',\n",
    "            'wisconsin',\n",
    "            'wyoming']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The steps to get a DataFrame from one page of results look like this:\n",
    "- Build a URL by combining the base url with a specific page number\n",
    "- Use requests.post() to get the results of the post\n",
    "- Make a soup from results.text\n",
    "- Look at the soup to identify the table you want based on one of its attributes (like class) \n",
    "- Pass the table as a string to pandas read_html() \n",
    "- What does that look like? What is the datatype?\n",
    "- Keep working with the data until you have it a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check to see the number of state names in the list \n",
    "len(state_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function takes tow parameter one as for the page name and another as the page base url \n",
    "def function_return_df ( pages, base='https://covidtracking.com/data/state/'):\n",
    "\n",
    "    \n",
    "        df=pd.DataFrame()\n",
    "\n",
    "    \n",
    "#combine both parameters\n",
    "        url = base+str(pages)\n",
    "    \n",
    "        response = requests.post(url)\n",
    "        soup = BS(response.text, 'lxml')\n",
    "   \n",
    "        tables = soup.find_all('table',\n",
    "                           attrs = {'class': 'table-module--table--1HfxU'})\n",
    "        result_list = pd.read_html(str(tables[1]))\n",
    "#turn the list to datframe\n",
    "        df = df.append( pd.DataFrame(result_list[0]) )\n",
    "        \n",
    "        #print(result_list[0])\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alabama\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f6c58400c019>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msizeofList\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mall_dfs_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunction_return_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#call the function to return the tables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-cb713ecc1a86>\u001b[0m in \u001b[0;36mfunction_return_df\u001b[1;34m(pages, base)\u001b[0m\n\u001b[0;32m     14\u001b[0m         tables = soup.find_all('table',\n\u001b[0;32m     15\u001b[0m                            attrs = {'class': 'table-module--table--1HfxU'})\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mresult_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;31m#turn the list to datframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "all_dfs_list=[]   #empty list for all dataframes\n",
    "\n",
    "i = 0\n",
    "\n",
    "sizeofList = len(state_names) \n",
    "\n",
    "while i < sizeofList :\n",
    "\n",
    "    all_dfs_list.append(function_return_df(state_names[i])) #call the function to return the tables\n",
    "    print(state_names[i])\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this codes do same work as the above while loop, this only another approach.\n",
    "#create an empty list to append each returned dataframe from the function_return_df\n",
    "#pass tow arguments to the function from both all_urls_list and pages_list.\n",
    "\n",
    "'''all_dfs_list=[]\n",
    "i=0\n",
    "for   state_namesIndex in  state_names:\n",
    "        print(state_names[i])\n",
    "        i+=1\n",
    "        all_dfs_list.append(function_return_df(state_namesIndex))\n",
    "        print(\"done\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================\n",
      "The number of saved tables is: 1\n"
     ]
    }
   ],
   "source": [
    "##use this cell if we run the first list of state_names\n",
    "#create a list of names we want for each dataframe\n",
    "names_list= ['Alabama',\n",
    "              'Alaska',\n",
    "#               'american-samoa',   #comment out any name not needed in both names_list and state_names\n",
    "               'Arizona',\n",
    "                 'Arkansas',\n",
    "              'California',\n",
    "            'Colorado',\n",
    "         'Connecticut',\n",
    "                     'Delaware',\n",
    "                      'District_of_Columbia',\n",
    "                'Florida',\n",
    "                'Georgia',\n",
    "                'Hawaii',\n",
    "                'Idaho',\n",
    "                 'Illinois',\n",
    "                  'Indiana',\n",
    "                   'Iowa',\n",
    "                'Kansas',\n",
    "             'Kentucky',\n",
    "                'Louisiana',\n",
    "                'Maine',\n",
    "                 'Maryland',\n",
    "                  'Massachusetts',\n",
    "                   'Michigan',\n",
    "                    'Minnesota',\n",
    "                     'Mississippi']\n",
    "#pass each dataframe and the name for it from both above created list \n",
    "\n",
    "for df, name in zip(all_dfs_list , names_list):\n",
    "    \n",
    "#save each dataframe by the given name into a csv file\n",
    "\n",
    "    df.to_csv(name + '_' + 'state' + '.csv', index= False)\n",
    "    \n",
    "print(\"============================================\")\n",
    "print(\"The number of saved tables is:\", len(all_dfs_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this cell if we run the second list of state_names\n",
    "#create a list of names we want for each dataframe\n",
    "names_list= ['Iowa',\n",
    "                'Kansas',\n",
    "             'Kentucky',\n",
    "                'Louisiana',\n",
    "                'Maine',\n",
    "                 'Maryland',\n",
    "                  'Massachusetts',\n",
    "                   'Michigan',\n",
    "                    'Minnesota',\n",
    "                     'Mississippi',\n",
    "               'Missouri',\n",
    "                 'Montana',\n",
    "                'Nebraska',\n",
    "               'Nevada',\n",
    "              'New_Hampshire',\n",
    "            'New_Jersey',\n",
    "          'New_Mexico',\n",
    "         'New_York',\n",
    "       'North_Carolina',\n",
    "      'North_Dakota',\n",
    "                'Ohio',\n",
    "                 'Oklahoma',\n",
    "                  'Oregon',\n",
    "                'Pennsylvania',\n",
    "               'Rhode_Island',\n",
    "                'South_Carolina',\n",
    "                 'South_Dakota',\n",
    "               'Tennessee',\n",
    "                'Texas',\n",
    "                'Utah',\n",
    "                'Vermont',\n",
    "                 'Virginia',\n",
    "                'Washington',\n",
    "              'West_Virginia',\n",
    "             'Wisconsin',\n",
    "            'Wyoming']\n",
    "#pass each dataframe and the name for it from both above created list \n",
    "\n",
    "for df, name in zip(all_dfs_list , names_list):\n",
    "    \n",
    "#save each dataframe by the given name into a csv file\n",
    "\n",
    "    df.to_csv(name + '_' + 'state' + '.csv'', index= False)\n",
    "    \n",
    "print(\"============================================\")\n",
    "print(\"The number of saved tables is:\", len(all_dfs_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
